<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Tracking Camera</title>
    <!-- Add TensorFlow.js and face-landmarks-detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #1a1a1a;
            color: #ffffff;
            line-height: 1.6;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .container {
            width: 100%;
            max-width: 1200px;
            padding: 1rem;
        }

        h1 {
            text-align: center;
            font-size: 2.5rem;
            margin: 1rem 0;
            color: #00ff88;
            text-transform: uppercase;
            letter-spacing: 2px;
            animation: glow 2s ease-in-out infinite alternate;
        }

        .video-container {
            background-color: #2a2a2a;
            padding: 1rem;
            border-radius: 10px;
            width: 100%;
            margin: 0 auto;
            position: relative;
            animation: redPulse 2s ease-in-out infinite;
        }

        .video-container::before {
            content: '';
            position: absolute;
            top: -3px;
            left: -3px;
            right: -3px;
            bottom: -3px;
            border-radius: 12px;
            background: linear-gradient(45deg, #ff0000, #ff6b6b);
            z-index: -1;
            animation: borderGlow 2s ease-in-out infinite alternate;
        }

        #videoElement {
            width: 100%;
            height: auto;
            border-radius: 5px;
            display: block;
            transform: scaleX(-1);
        }

        #canvasElement {
            position: absolute;
            top: 1rem;
            left: 1rem;
            transform: scaleX(-1);
        }

        .camera-controls {
            margin-top: 1rem;
            display: flex;
            justify-content: center;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .control-btn {
            padding: 0.8rem 1.5rem;
            border: none;
            border-radius: 5px;
            background-color: #00ff88;
            color: #1a1a1a;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .control-btn:hover {
            background-color: #00cc6a;
        }

        .control-btn.stop {
            background-color: #ff4444;
        }

        .control-btn.stop:hover {
            background-color: #cc3333;
        }

        .stats {
            position: absolute;
            top: 1.5rem;
            left: 1.5rem;
            background-color: rgba(0, 0, 0, 0.6);
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.9rem;
            z-index: 10;
        }

        @keyframes glow {
            from { text-shadow: 0 0 5px #00ff88, 0 0 10px #00ff88; }
            to { text-shadow: 0 0 10px #00ff88, 0 0 20px #00ff88; }
        }

        @keyframes redPulse {
            0% { box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3); }
            50% { box-shadow: 0 0 20px rgba(255, 0, 0, 0.5), 0 0 30px rgba(255, 0, 0, 0.3); }
            100% { box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3); }
        }

        @keyframes borderGlow {
            0% { opacity: 0.5; filter: blur(3px); }
            100% { opacity: 0.8; filter: blur(5px); }
        }

        .live-indicator {
            position: absolute;
            top: 1.5rem;
            right: 1.5rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            background-color: rgba(0, 0, 0, 0.6);
            padding: 0.5rem 1rem;
            border-radius: 20px;
            z-index: 10;
        }

        .record-dot {
            width: 10px;
            height: 10px;
            background-color: #ff0000;
            border-radius: 50%;
            animation: recordBlink 1s ease-in-out infinite;
        }

        @keyframes recordBlink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.4; }
        }

        @media (max-width: 768px) {
            .container { padding: 0.5rem; }
            h1 { font-size: 2rem; margin: 0.5rem 0; }
            .live-indicator {
                top: 1rem;
                right: 1rem;
                padding: 0.3rem 0.8rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Face Tracking</h1>
        <div class="video-container">
            <div class="live-indicator">
                <div class="record-dot"></div>
                <span>LIVE</span>
            </div>
            <div class="stats">
                <div id="fps">FPS: 0</div>
                <div id="confidence">Confidence: 0%</div>
            </div>
            <video id="videoElement" autoplay playsinline></video>
            <canvas id="canvasElement"></canvas>
        </div>
        <div class="camera-controls">
            <button class="control-btn start">Start Camera</button>
            <button class="control-btn stop">Stop Camera</button>
            <button class="control-btn switch">Switch Camera</button>
            <button class="control-btn toggle-track">Toggle Tracking</button>
        </div>
    </div>

    <script>
        const videoElement = document.getElementById('videoElement');
        const canvasElement = document.getElementById('canvasElement');
        const canvasCtx = canvasElement.getContext('2d');
        const startButton = document.querySelector('.control-btn.start');
        const stopButton = document.querySelector('.control-btn.stop');
        const switchButton = document.querySelector('.control-btn.switch');
        const toggleTrackButton = document.querySelector('.control-btn.toggle-track');
        const fpsElement = document.getElementById('fps');
        const confidenceElement = document.getElementById('confidence');

        let currentStream = null;
        let facingMode = "user";
        let model = null;
        let isTracking = false;
        let lastTime = Date.now();
        let frameCount = 0;

        // Load the face detection model
        async function loadModel() {
            try {
                model = await faceLandmarksDetection.load(
                    faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,
                    { maxFaces: 1 }
                );
                toggleTrackButton.disabled = false;
            } catch (err) {
                console.error("Error loading model:", err);
                alert("Error loading face tracking model. Please try again.");
            }
        }

        // Initialize face tracking
        loadModel();

        async function startCamera() {
            try {
                if (currentStream) {
                    currentStream.getTracks().forEach(track => track.stop());
                }

                const constraints = {
                    video: {
                        facingMode: facingMode,
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    },
                    audio: false
                };

                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                videoElement.srcObject = stream;
                currentStream = stream;

                // Set canvas size after video loads
                videoElement.onloadedmetadata = () => {
                    canvasElement.width = videoElement.videoWidth;
                    canvasElement.height = videoElement.videoHeight;
                };

                if (isTracking) {
                    requestAnimationFrame(detectFaces);
                }
            } catch (err) {
                console.error("Error accessing camera:", err);
                alert("Error accessing camera. Please make sure you've granted camera permissions.");
            }
        }

        function stopCamera() {
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
                videoElement.srcObject = null;
                currentStream = null;
            }
            isTracking = false;
        }

        function switchCamera() {
            facingMode = facingMode === "user" ? "environment" : "user";
            startCamera();
        }

        async function detectFaces() {
            if (!isTracking || !model || !currentStream) return;

            try {
                const predictions = await model.estimateFaces({
                    input: videoElement,
                    returnTensors: false,
                    flipHorizontal: false,
                    predictIrises: true
                });

                // Clear the canvas
                canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

                // Draw face landmarks
                predictions.forEach(face => {
                    // Draw face mesh
                    canvasCtx.strokeStyle = '#00ff88';
                    canvasCtx.lineWidth = 1;

                    // Draw face mesh points
                    face.scaledMesh.forEach(point => {
                        canvasCtx.beginPath();
                        canvasCtx.arc(point[0], point[1], 1, 0, 3 * Math.PI);
                        canvasCtx.stroke();
                    });

                    // Update confidence
                    confidenceElement.textContent = `Confidence: ${(face.faceInViewConfidence * 100).toFixed(1)}%`;
                });

                // Calculate and update FPS
                frameCount++;
                const currentTime = Date.now();
                if (currentTime - lastTime >= 1000) {
                    fpsElement.textContent = `FPS: ${frameCount}`;
                    frameCount = 0;
                    lastTime = currentTime;
                }

                requestAnimationFrame(detectFaces);
            } catch (err) {
                console.error("Error in face detection:", err);
            }
        }

        function toggleTracking() {
            isTracking = !isTracking;
            toggleTrackButton.textContent = isTracking ? 'Stop Tracking' : 'Start Tracking';
            if (isTracking && currentStream) {
                requestAnimationFrame(detectFaces);
            }
        }

        // Event listeners
        startButton.addEventListener('click', startCamera);
        stopButton.addEventListener('click', stopCamera);
        switchButton.addEventListener('click', switchCamera);
        toggleTrackButton.addEventListener('click', toggleTracking);

        // Check for camera support
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            alert("Your browser doesn't support camera access");
        }
    </script>
</body>
</html>